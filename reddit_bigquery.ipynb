{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data with BigQuery\n",
    "\n",
    "by [Max Woolf](http://minimaxir.com)\n",
    "\n",
    "This notebook is the complement for my blog post [How to Analyze Every Reddit Submission and Comment, in Seconds, for Free](http://minimaxir.com/2015/10/reddit-bigquery/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "\n",
    "# IMPORTANT: This assumes that all packages in \"Rstart.R\" are installed,\n",
    "# and the fonts \"Source Sans Pro\" and \"Open Sans Condensed Bold\" are installed\n",
    "# via extrafont. If ggplot2 charts fail to render, you may need to change/remove the theme call.\n",
    "\n",
    "source(\"Rstart.R\")\n",
    "library(tidyr)\n",
    "library(bigrquery)\n",
    "library(methods) # needed for query_exec in Jupyter: https://github.com/hadley/bigrquery/issues/32\n",
    "library(wordcloud)\n",
    "library(digest)\n",
    "\n",
    "options(repr.plot.mimetypes = 'image/png', repr.plot.width=4, repr.plot.height=3, repr.plot.res=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbigquery\n",
    "\n",
    "This uses the `rbigquery` R package to query the data. Ensure that it is set up correctly, with your own project name from BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_name <- <FILL IN>   # DO NOT SHARE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World!\n",
    "\n",
    "Simple query to test things out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>date_submission</th><th scope=col>num_submissions</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>2015-08-23</td><td>170999</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2015-08-24</td><td>163107</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2015-08-25</td><td>264787</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2015-08-26</td><td>235858</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2015-08-27</td><td>212472</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>2015-08-28</td><td>206100</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>2015-08-29</td><td>180039</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>2015-08-30</td><td>183686</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>2015-08-31</td><td>214685</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>2015-09-01</td><td>10299</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & date_submission & num_submissions\\\\\n",
       "\\hline\n",
       "\t1 & 2015-08-23 & 170999\\\\\n",
       "\t2 & 2015-08-24 & 163107\\\\\n",
       "\t3 & 2015-08-25 & 264787\\\\\n",
       "\t4 & 2015-08-26 & 235858\\\\\n",
       "\t5 & 2015-08-27 & 212472\\\\\n",
       "\t6 & 2015-08-28 & 206100\\\\\n",
       "\t7 & 2015-08-29 & 180039\\\\\n",
       "\t8 & 2015-08-30 & 183686\\\\\n",
       "\t9 & 2015-08-31 & 214685\\\\\n",
       "\t10 & 2015-09-01 & 10299\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [10 x 2]\n",
       "\n",
       "   date_submission num_submissions\n",
       "             (chr)           (int)\n",
       "1       2015-08-23          170999\n",
       "2       2015-08-24          163107\n",
       "3       2015-08-25          264787\n",
       "4       2015-08-26          235858\n",
       "5       2015-08-27          212472\n",
       "6       2015-08-28          206100\n",
       "7       2015-08-29          180039\n",
       "8       2015-08-30          183686\n",
       "9       2015-08-31          214685\n",
       "10      2015-09-01           10299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql <- \"SELECT DATE(SEC_TO_TIMESTAMP(created)) date_submission,\n",
    "COUNT(*) as num_submissions\n",
    "FROM [fh-bigquery:reddit_posts.full_corpus_201509]\n",
    "GROUP BY date_submission\n",
    "ORDER by date_submission\"\n",
    "\n",
    "df <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\n",
    "df %>% tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it in ggplot2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot <- ggplot(df, aes(x=as.Date(date_submission), y=num_submissions)) +\n",
    "            geom_area(fill=\"#2980b9\", alpha=0.85, size=0) +\n",
    "            fte_theme() +\n",
    "            scale_x_date(breaks=date_breaks(\"1 year\"), labels=date_format(\"%Y\")) +\n",
    "            scale_y_continuous(breaks=pretty_breaks(8), labels=comma) +\n",
    "            labs(x=\"Date of Submission\", y=\"# of Submissions\", title=\"Daily # of Reddit Submissions from 2006 - 2015\")\n",
    "\n",
    "max_save(plot, \"reddit-bigquery-1\", \"Reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](reddit-bigquery-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is the best time to submit to reddit for virality?\n",
    "\n",
    "Create heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>sub_dayofweek</th><th scope=col>sub_hour</th><th scope=col>num_gte_3000</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>7</td><td>14</td><td>1001</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>7</td><td>15</td><td>893</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>7</td><td>16</td><td>890</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>7</td><td>17</td><td>806</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>7</td><td>18</td><td>807</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>7</td><td>19</td><td>763</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>7</td><td>20</td><td>769</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>7</td><td>21</td><td>705</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>7</td><td>22</td><td>620</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>7</td><td>23</td><td>505</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & sub_dayofweek & sub_hour & num_gte_3000\\\\\n",
       "\\hline\n",
       "\t1 & 7 & 14 & 1001\\\\\n",
       "\t2 & 7 & 15 & 893\\\\\n",
       "\t3 & 7 & 16 & 890\\\\\n",
       "\t4 & 7 & 17 & 806\\\\\n",
       "\t5 & 7 & 18 & 807\\\\\n",
       "\t6 & 7 & 19 & 763\\\\\n",
       "\t7 & 7 & 20 & 769\\\\\n",
       "\t8 & 7 & 21 & 705\\\\\n",
       "\t9 & 7 & 22 & 620\\\\\n",
       "\t10 & 7 & 23 & 505\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [10 x 3]\n",
       "\n",
       "   sub_dayofweek sub_hour num_gte_3000\n",
       "           (int)    (int)        (int)\n",
       "1              7       14         1001\n",
       "2              7       15          893\n",
       "3              7       16          890\n",
       "4              7       17          806\n",
       "5              7       18          807\n",
       "6              7       19          763\n",
       "7              7       20          769\n",
       "8              7       21          705\n",
       "9              7       22          620\n",
       "10             7       23          505"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql <- \"SELECT\n",
    "  DAYOFWEEK(SEC_TO_TIMESTAMP(created - 60*60*5)) as sub_dayofweek,\n",
    "  HOUR(SEC_TO_TIMESTAMP(created - 60*60*5)) as sub_hour,\n",
    "  SUM(IF(score >= 3000, 1, 0)) as num_gte_3000,\n",
    "FROM [fh-bigquery:reddit_posts.full_corpus_201509]\n",
    "GROUP BY sub_dayofweek, sub_hour\n",
    "ORDER BY sub_dayofweek, sub_hour\"\n",
    "\n",
    "df <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\n",
    "df %>% tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few tweaks to format Time aliases into readable representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining by: \"sub_dayofweek\"\n",
      "Joining by: \"sub_hour\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>sub_dayofweek</th><th scope=col>sub_hour</th><th scope=col>num_gte_3000</th><th scope=col>dow_format</th><th scope=col>hour_format</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>7</td><td>14</td><td>1001</td><td>Saturday</td><td>2 PM</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>7</td><td>15</td><td>893</td><td>Saturday</td><td>3 PM</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>7</td><td>16</td><td>890</td><td>Saturday</td><td>4 PM</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>7</td><td>17</td><td>806</td><td>Saturday</td><td>5 PM</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>7</td><td>18</td><td>807</td><td>Saturday</td><td>6 PM</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>7</td><td>19</td><td>763</td><td>Saturday</td><td>7 PM</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>7</td><td>20</td><td>769</td><td>Saturday</td><td>8 PM</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>7</td><td>21</td><td>705</td><td>Saturday</td><td>9 PM</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>7</td><td>22</td><td>620</td><td>Saturday</td><td>10 PM</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>7</td><td>23</td><td>505</td><td>Saturday</td><td>11 PM</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & sub_dayofweek & sub_hour & num_gte_3000 & dow_format & hour_format\\\\\n",
       "\\hline\n",
       "\t1 & 7 & 14 & 1001 & Saturday & 2 PM\\\\\n",
       "\t2 & 7 & 15 & 893 & Saturday & 3 PM\\\\\n",
       "\t3 & 7 & 16 & 890 & Saturday & 4 PM\\\\\n",
       "\t4 & 7 & 17 & 806 & Saturday & 5 PM\\\\\n",
       "\t5 & 7 & 18 & 807 & Saturday & 6 PM\\\\\n",
       "\t6 & 7 & 19 & 763 & Saturday & 7 PM\\\\\n",
       "\t7 & 7 & 20 & 769 & Saturday & 8 PM\\\\\n",
       "\t8 & 7 & 21 & 705 & Saturday & 9 PM\\\\\n",
       "\t9 & 7 & 22 & 620 & Saturday & 10 PM\\\\\n",
       "\t10 & 7 & 23 & 505 & Saturday & 11 PM\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [10 x 5]\n",
       "\n",
       "   sub_dayofweek sub_hour num_gte_3000 dow_format hour_format\n",
       "           (int)    (int)        (int)      (chr)       (chr)\n",
       "1              7       14         1001   Saturday        2 PM\n",
       "2              7       15          893   Saturday        3 PM\n",
       "3              7       16          890   Saturday        4 PM\n",
       "4              7       17          806   Saturday        5 PM\n",
       "5              7       18          807   Saturday        6 PM\n",
       "6              7       19          763   Saturday        7 PM\n",
       "7              7       20          769   Saturday        8 PM\n",
       "8              7       21          705   Saturday        9 PM\n",
       "9              7       22          620   Saturday       10 PM\n",
       "10             7       23          505   Saturday       11 PM"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow_format <- data_frame(sub_dayofweek = 1:7, dow_format = c(\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"))\n",
    "\n",
    "hour_format <- data_frame(sub_hour = 0:23, hour_format = c(paste(c(12,1:11),\"AM\"), paste(c(12,1:11),\"PM\")))\n",
    "\n",
    "df_time <- df %>% left_join(dow_format) %>% left_join(hour_format)\n",
    "\n",
    "df_time %>% tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary for correct order when plotting.\n",
    "df_time$dow_format <- factor(df_time$dow_format, level = rev(dow_format$dow_format))\n",
    "df_time$hour_format <- factor(df_time$hour_format, level = hour_format$hour_format)\n",
    "\n",
    "plot <- ggplot(df_time, aes(x=hour_format, y=dow_format, fill=num_gte_3000)) +\n",
    "    geom_tile() +\n",
    "    fte_theme() +\n",
    "    theme(axis.text.x = element_text(angle = 90, vjust = 0.6), legend.title = element_blank(), legend.position=\"top\", legend.direction=\"horizontal\", legend.key.width=unit(1, \"cm\"), legend.key.height=unit(0.25, \"cm\"), legend.margin=unit(-0.5,\"cm\"), panel.margin=element_blank()) +\n",
    "    labs(x = \"Hour of Reddit Submission (Eastern Standard Time)\", y = \"Day of Week of Reddit Submission\", title = \"# of Reddit Submissions Which Received >3000 Points, by Time of Original Submission\") +\n",
    "    scale_fill_gradient(low = \"white\", high = \"#27ae60\", labels=comma, breaks=pretty_breaks(6))\n",
    "\n",
    "max_save(plot, \"reddit-bigquery-2\", \"Reddit\", w=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](reddit-bigquery-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which words in comments lead to the most upvotes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running query:   RUNNING  2.1s\r",
      "Running query:   RUNNING  2.7s\r",
      "Running query:   RUNNING  3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.3 gigabytes processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>word</th><th scope=col>num_words</th><th scope=col>avg_score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>the</td><td>860688</td><td>10.56031</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>to</td><td>566054</td><td>9.885569</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>a</td><td>510322</td><td>9.933583</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>and</td><td>419449</td><td>10.13845</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>of</td><td>387376</td><td>9.68622</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>that</td><td>319336</td><td>8.988705</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>is</td><td>310461</td><td>8.917468</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>i</td><td>291533</td><td>8.348729</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>you</td><td>283140</td><td>6.48695</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>in</td><td>277130</td><td>9.831895</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & word & num_words & avg_score\\\\\n",
       "\\hline\n",
       "\t1 & the & 860688 & 10.56031\\\\\n",
       "\t2 & to & 566054 & 9.885569\\\\\n",
       "\t3 & a & 510322 & 9.933583\\\\\n",
       "\t4 & and & 419449 & 10.13845\\\\\n",
       "\t5 & of & 387376 & 9.68622\\\\\n",
       "\t6 & that & 319336 & 8.988705\\\\\n",
       "\t7 & is & 310461 & 8.917468\\\\\n",
       "\t8 & i & 291533 & 8.348729\\\\\n",
       "\t9 & you & 283140 & 6.48695\\\\\n",
       "\t10 & in & 277130 & 9.831895\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [10 x 3]\n",
       "\n",
       "    word num_words avg_score\n",
       "   (chr)     (int)     (dbl)\n",
       "1    the    860688 10.560306\n",
       "2     to    566054  9.885569\n",
       "3      a    510322  9.933583\n",
       "4    and    419449 10.138446\n",
       "5     of    387376  9.686220\n",
       "6   that    319336  8.988705\n",
       "7     is    310461  8.917468\n",
       "8      i    291533  8.348729\n",
       "9    you    283140  6.486950\n",
       "10    in    277130  9.831895"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In R, note that the backslashes and quotes are escaped.\n",
    "\n",
    "sql <- \"SELECT word, COUNT(*) as num_words, AVG(score) as avg_score\n",
    "FROM(FLATTEN((\n",
    "  SELECT SPLIT(LOWER(REGEXP_REPLACE(body, r'[\\\\.\\\\\\\",*:()\\\\[\\\\]/|\\\\n]', ' ')), ' ') word, score\n",
    "  FROM [fh-bigquery:reddit_comments.2015_08] \n",
    "  WHERE author NOT IN (SELECT author FROM [fh-bigquery:reddit_comments.bots_201505])\n",
    "    AND subreddit=\\\"news\\\"\n",
    "  ), word))\n",
    "GROUP EACH BY word\n",
    "HAVING num_words >= 10000\n",
    "ORDER BY num_words DESC\"\n",
    "\n",
    "df <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\n",
    "df %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a wordcloud using the `wordcloud` package. (I may do a seperate post on how to make Wordclouds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words <- unlist(strsplit(\"a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your,id,item,it\\'s,don\\'t\",\",\"))\n",
    "\n",
    "pal <- brewer.pal(9, \"Purples\")\n",
    "pal <- pal[-c(1:3)]   # Remove light colors\n",
    "\n",
    "df_nostop <- df %>% filter(!(word %in% stop_words))\n",
    "\n",
    "png(filename = \"reddit-bigquery-3.png\", width = 1000, height = 1000, res= 300)\n",
    "\n",
    "wordcloud(toupper(df_nostop$word),\n",
    "          df_nostop$num_words,\n",
    "          scale=c(5,.1),\n",
    "          random.order=F,\n",
    "          rot.per=.10,\n",
    "          max.words=5000,\n",
    "          colors=pal,\n",
    "          family=\"Avenir Next Condensed Bold\",\n",
    "          random.color=T)\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](reddit-bigquery-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Comment Monthly Active Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running query:   RUNNING  2.5s\r",
      "Running query:   RUNNING  4.0s\r",
      "Running query:   RUNNING  4.6s\r",
      "Running query:   RUNNING  5.2s\r",
      "Running query:   RUNNING  5.8s\r",
      "Running query:   RUNNING  6.4s\r",
      "Running query:   RUNNING  7.0s\r",
      "Running query:   RUNNING  7.6s\r",
      "Running query:   RUNNING  8.3s\r",
      "Running query:   RUNNING  8.9s\r",
      "Running query:   RUNNING  9.5s\r",
      "Running query:   RUNNING 10.1s\r",
      "Running query:   RUNNING 10.7s\r",
      "Running query:   RUNNING 11.3s\r",
      "Running query:   RUNNING 11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53.3 gigabytes processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>subreddit</th><th scope=col>date</th><th scope=col>unique_authors</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>news</td><td>2015-08</td><td>107419</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>gifs</td><td>2015-08</td><td>106822</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>movies</td><td>2015-08</td><td>101296</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>AdviceAnimals</td><td>2015-08</td><td>99190</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>Showerthoughts</td><td>2015-08</td><td>76849</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>aww</td><td>2015-08</td><td>71682</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>IAmA</td><td>2015-08</td><td>67675</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>explainlikeimfive</td><td>2015-08</td><td>60421</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>mildlyinteresting</td><td>2015-08</td><td>60346</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>Music</td><td>2015-08</td><td>59769</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & subreddit & date & unique_authors\\\\\n",
       "\\hline\n",
       "\t1 & news & 2015-08 & 107419\\\\\n",
       "\t2 & gifs & 2015-08 & 106822\\\\\n",
       "\t3 & movies & 2015-08 & 101296\\\\\n",
       "\t4 & AdviceAnimals & 2015-08 & 99190\\\\\n",
       "\t5 & Showerthoughts & 2015-08 & 76849\\\\\n",
       "\t6 & aww & 2015-08 & 71682\\\\\n",
       "\t7 & IAmA & 2015-08 & 67675\\\\\n",
       "\t8 & explainlikeimfive & 2015-08 & 60421\\\\\n",
       "\t9 & mildlyinteresting & 2015-08 & 60346\\\\\n",
       "\t10 & Music & 2015-08 & 59769\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Source: local data frame [10 x 3]\n",
       "\n",
       "           subreddit    date unique_authors\n",
       "               (chr)   (chr)          (int)\n",
       "1               news 2015-08         107419\n",
       "2               gifs 2015-08         106822\n",
       "3             movies 2015-08         101296\n",
       "4      AdviceAnimals 2015-08          99190\n",
       "5     Showerthoughts 2015-08          76849\n",
       "6                aww 2015-08          71682\n",
       "7               IAmA 2015-08          67675\n",
       "8  explainlikeimfive 2015-08          60421\n",
       "9  mildlyinteresting 2015-08          60346\n",
       "10             Music 2015-08          59769"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query is about 53GB; use with caution!\n",
    "\n",
    "sql <- \"SELECT subreddit, date, unique_authors FROM\n",
    "(SELECT subreddit, date, unique_authors, ROW_NUMBER() OVER (PARTITION BY date ORDER BY unique_authors DESC) rank FROM\n",
    "(SELECT subreddit, LEFT(DATE(SEC_TO_TIMESTAMP(created_utc)), 7) as date, COUNT(UNIQUE(author)) as unique_authors\n",
    "FROM TABLE_QUERY([fh-bigquery:reddit_comments], \\\"table_id CONTAINS \\'20\\' AND LENGTH(table_id)<8\\\")\n",
    "GROUP EACH BY subreddit, date\n",
    "))\n",
    "WHERE rank <= 20\n",
    "ORDER BY date ASC, unique_authors DESC\"\n",
    "\n",
    "df <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\n",
    "df %>% tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_subreddit <- df %>% mutate(date_format=paste(date,\"-01\",sep=''))\n",
    "\n",
    "system(\"mkdir -p subreddit-ranks\")\n",
    "\n",
    "# Assign colors to subreddits at random using a hash of subreddit name\n",
    "\n",
    "colorHash <- function(strings) {\n",
    "    colors <- color_palette\n",
    "    \n",
    "    if (strtoi(substr(digest(strings),1,6), base=36) %% length(colors) == 0) { return (\"#999999\") }\n",
    "    return (colors[strtoi(substr(digest(strings),1,6), base=36) %% length(colors)])\n",
    "}\n",
    "\n",
    "subredditPlot <- function(month) {\n",
    "    df_subset <- df_subreddit %>% filter(date_format==month)\n",
    "    \n",
    "    subreddit_colors <- unlist(lapply(df_subset$subreddit, colorHash))\n",
    "\n",
    "    df_subset$subreddit <- factor(df_subset$subreddit, levels=rev(df_subset$subreddit))\n",
    "        \n",
    "    left_labels <- ifelse(df_subset$unique_authors > max(df_subset$unique_authors) * 0.90,\n",
    "                             format(df_subset$unique_authors, big.mark=\",\"), '')\n",
    "    right_labels <- ifelse(df_subset$unique_authors < max(df_subset$unique_authors) * 0.90,\n",
    "                             format(df_subset$unique_authors, big.mark=\",\"), '')\n",
    "    \n",
    "    plot <- ggplot(df_subset, aes(x=subreddit, y=unique_authors, fill=subreddit)) +\n",
    "                geom_bar(stat=\"identity\") +\n",
    "                geom_text(label=left_labels, size=2, hjust=1.25, color=\"white\", family=\"Open Sans Condensed Bold\") +\n",
    "                geom_text(label=right_labels, size=2, hjust=-0.25, color=subreddit_colors, family=\"Open Sans Condensed Bold\") +\n",
    "                fte_theme() +\n",
    "                coord_flip() +\n",
    "                scale_y_continuous(labels=comma, breaks=pretty_breaks(6)) +\n",
    "                scale_fill_manual(values=rev(subreddit_colors)) +\n",
    "                theme(axis.text.y = element_text(color=rev(subreddit_colors)), plot.title=element_text(hjust=1), axis.title.y=element_blank()) +\n",
    "                labs(y=\"Monthly Unique Commenters in Subreddit\", title=sprintf(\"Subreddits with Greatest # of Distinct Comment Authors in %s\", format(as.Date(month), \"%B %Y\")))\n",
    "    \n",
    "                         \n",
    "    max_save(plot, sprintf(\"subreddit-ranks/%s\", month), \"Reddit\")\n",
    "    \n",
    "}\n",
    "\n",
    "subredditPlot(\"2015-08-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](subreddit-ranks/2015-08-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the `subredditPlot` function to create each frame for the GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date <- \"2010-08-01\"\n",
    "\n",
    "months <- as.character(seq(as.Date(start_date), as.Date(\"2015-08-01\"), \"months\"))\n",
    "\n",
    "x <- lapply(months, subredditPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](subreddit-ranks.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
